{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project - Pawpularity ##\n",
    "### Armando Fortes (2021403383), David Pissarra (2021403381)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(f'Number of GPUs available: {len(physical_devices)}')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and Hyperparameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '../Dataset/'\n",
    "train_images_path = dataset_dir + 'train/'\n",
    "test_images_path = dataset_dir + 'test/'\n",
    "train_meta_path = dataset_dir + 'train.csv'\n",
    "test_meta_path = dataset_dir + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STRAT_SIZE = 20\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_DIM = 128\n",
    "BUFFER_SIZE = 1024\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Dataset Preprocessing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    image = tf.image.resize(image, (IMAGE_DIM, IMAGE_DIM))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image(image_path, label):\n",
    "    return load_image(image_path), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_distribution(df, attr, value, color=\"dodgerblue\"):\n",
    "    plt.title(f\"{attr} = {value}\")\n",
    "    x = df.loc[df[attr] == value]['Pawpularity']\n",
    "    x.plot(kind='hist', bins=20, color=color)\n",
    "\n",
    "    _, max_ylim = plt.ylim()\n",
    "    plt.axvline(x.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.text(x.mean()*1.1, max_ylim*0.9, 'Mean: {:.2f}'.format(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(train_meta_path).sort_values(by='Id')\n",
    "train_metadata = train_metadata.assign(Strat=(train_metadata['Pawpularity']//STRAT_SIZE))\n",
    "images_names = (train_images_path + train_metadata['Id'] + '.jpg').values\n",
    "images_paws = (train_metadata['Pawpularity']).values\n",
    "images_strats = (train_metadata['Strat']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 13))\n",
    "columns = 4\n",
    "rows = 6\n",
    "set = 1\n",
    "\n",
    "for attr in train_metadata.columns:\n",
    "    if attr not in ('Id', 'Pawpularity', 'Strat'):\n",
    "        fig.add_subplot(rows, columns, set)\n",
    "        attr_distribution(train_metadata, attr, 0, color='orange')\n",
    "        fig.add_subplot(rows, columns, set + 1)\n",
    "        attr_distribution(train_metadata, attr, 1)\n",
    "        set += 2\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_names, valid_images_names, Y_train, Y_valid = train_test_split(\n",
    "    images_names,\n",
    "    images_strats,\n",
    "    test_size=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((train_images_names, Y_train))\n",
    "ds_train = ds_train.map(map_image, num_parallel_calls=AUTOTUNE)\n",
    "# ds_train = ds_train.repeat()\n",
    "ds_train = ds_train.shuffle(buffer_size=BUFFER_SIZE, reshuffle_each_iteration=True)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# for x in ds_test:\n",
    "#     plt.imshow(x[0].numpy())\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid = tf.data.Dataset.from_tensor_slices((valid_images_names, Y_valid))\n",
    "ds_valid = ds_valid.map(map_image, num_parallel_calls=AUTOTUNE)\n",
    "ds_valid = ds_valid.batch(1)\n",
    "ds_valid = ds_valid.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv(test_meta_path).sort_values(by='Id')\n",
    "test_images_names = (test_images_path + test_metadata['Id'] + '.jpg').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = tf.data.Dataset.from_tensor_slices((test_images_names,))\n",
    "ds_test = ds_test.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.prefetch(AUTOTUNE)\n",
    "\n",
    "# for x in ds_test:\n",
    "#     plt.imshow(x[0].numpy())\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and training ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_DIM, IMAGE_DIM, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(100//STRAT_SIZE, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss=MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train, epochs=EPOCHS, validation_data=ds_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = model.predict(ds_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame()\n",
    "test_predictions['Id'] = test_metadata.Id\n",
    "test_predictions['Pawpularity'] = yhat_test\n",
    "test_predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.head(8)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52143a4c1d3c54e78ec3a6dc4e56afb88afff4ca0e9824f0ff9251ac34bb2b12"
  },
  "kernelspec": {
   "display_name": "PyCharm (Project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
