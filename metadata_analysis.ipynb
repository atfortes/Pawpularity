{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning Project - Pawpularity - Metadata Analysis**\n",
    "### Armando Fortes (2021403383), David Pissarra (2021403381)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, KFold, cross_validate, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and Hyperparameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '../Dataset/'\n",
    "train_metadata_path = dataset_dir + 'train.csv'\n",
    "test_metadata_path = dataset_dir + 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = 4\n",
    "REPEATS = 2\n",
    "RANDOM_SEED = 0\n",
    "PCA_COMPONENTS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(train_metadata_path).sort_values(by='Id')\n",
    "X_train = train_metadata.iloc[:,2:-1]\n",
    "y_train = train_metadata['Pawpularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = pd.read_csv(test_metadata_path).sort_values(by='Id')\n",
    "X_test = test_metadata.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_distribution(df, attr, value, color=\"dodgerblue\"):\n",
    "    x = df.loc[df[attr] == value]['Pawpularity']\n",
    "    x.plot(kind='hist', bins=20, title=f'{attr} = {value}', color=color, xlabel='Pawpularity')\n",
    "\n",
    "    _, max_ylim = plt.ylim()\n",
    "    plt.axvline(x.mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.text(x.mean()*1.1, max_ylim*0.9, 'Mean: {:.2f}'.format(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 13))\n",
    "columns = 4\n",
    "rows = 6\n",
    "set = 1\n",
    "\n",
    "for attr in train_metadata.columns:\n",
    "    if attr not in ('Id', 'Pawpularity', 'Bin'):\n",
    "        fig.add_subplot(rows, columns, set)\n",
    "        attr_distribution(train_metadata, attr, 0, color='orange')\n",
    "        fig.add_subplot(rows, columns, set + 1)\n",
    "        attr_distribution(train_metadata, attr, 1)\n",
    "        set += 2\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit(X_train)\n",
    "X_train = X_train.join(pd.DataFrame(pca.transform(X_train), index=X_train.index).add_prefix('pca_'))\n",
    "X_test = X_test.join(pd.DataFrame(pca.transform(X_test), index=X_test.index).add_prefix('pca_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\n",
    "    'XGBRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'KNeighborsRegressor',\n",
    "    'BernoulliNB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'XGBRegressor': XGBRegressor(n_jobs=-1),\n",
    "    'LGBMRegressor': LGBMRegressor(),\n",
    "    'CatBoostRegressor': CatBoostRegressor(iterations=900, depth=5, learning_rate=0.05, loss_function = 'RMSE'),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=RANDOM_SEED),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=10),\n",
    "    'BernoulliNB': BernoulliNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=SPLITS, n_repeats=REPEATS, random_state=0)\n",
    "    scores = cross_validate(model, X_train, y_train, scoring='neg_mean_squared_error', cv=cv, return_estimator=True, n_jobs=-1)\n",
    "\n",
    "    trained[name] = scores['estimator']\n",
    "\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    for estimator in scores['estimator']:\n",
    "        predictions += estimator.predict(X_test)\n",
    "    predictions /= len(scores['estimator'])\n",
    "    \n",
    "    rmse = np.sqrt(-scores['test_score'])\n",
    "\n",
    "    print('='*int((80-len(name))/2), name, '='*int((80-len(name))/2))\n",
    "    print('RMSE:', '{0:.4f}'.format(np.mean(rmse)), 'std:', '{0:.4f}'.format(np.std(rmse)))\n",
    "    print('Predictions:', np.round(predictions), 'std:', '{0:.4f}'.format(np.std(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "        'XGBRegressor': np.zeros(X_train.shape[0]),\n",
    "        'LGBMRegressor': np.zeros(X_train.shape[0]),\n",
    "        'CatBoostRegressor': np.zeros(X_train.shape[0]),\n",
    "        'GradientBoostingRegressor': np.zeros(X_train.shape[0]),\n",
    "        'KNeighborsRegressor': np.zeros(X_train.shape[0]),\n",
    "        'BernoulliNB': np.zeros(X_train.shape[0]),\n",
    "    }\n",
    "\n",
    "for name, instances in trained.items():\n",
    "    for instance in instances:\n",
    "        predictions[name] += instance.predict(X_train)\n",
    "    predictions[name] /= len(instances)\n",
    "    print(name, np.sqrt(mean_squared_error(predictions[name], y_train.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_objective(trial):\n",
    "    X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [1, 2, 3, 4]),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [200, 300, 400, 500]),\n",
    "        'min_child_weight': trial.suggest_categorical('min_child_weight', [1, 2, 3, 4]),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 0.7),\n",
    "        'eta': trial.suggest_float('eta', 0.05, 0.5),\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': RANDOM_SEED\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params, n_jobs=-1)\n",
    "\n",
    "    fit_params = {\n",
    "        'eval_metric': 'rmse',\n",
    "        'eval_set': [(X_train_split, y_train_split), (X_valid_split, y_valid_split)],\n",
    "        'early_stopping_rounds': 400,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    model.fit(X_train_split, y_train_split, **fit_params)\n",
    "\n",
    "    return np.sqrt(mean_squared_error(model.predict(X_valid_split), y_valid_split.to_numpy()))\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(xgboost_objective, n_trials=1000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52143a4c1d3c54e78ec3a6dc4e56afb88afff4ca0e9824f0ff9251ac34bb2b12"
  },
  "kernelspec": {
   "display_name": "PyCharm (Project)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
